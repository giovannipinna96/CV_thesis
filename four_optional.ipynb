{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv2\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import optimizers, initializers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten,Dropout, MaxPooling2D, AveragePooling2D\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, History\n",
    "\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import import_ipynb\n",
    "import dataSetUtility as dsu\n",
    "import plottingUtility as pltu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from PIL import Image\n",
    "import tifffile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import tensorflow as tf\n",
    "import seaborn as sn\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "\n",
    "import random\n",
    "import PIL\n",
    "import os\n",
    "import cv2 as cv2\n",
    "import itertools\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path to the directories\n",
    "pathTrain=r'C:\\Users\\39320\\Desktop\\tesi\\Computer-Vision-2020-main\\ImageSet\\train'\n",
    "pathTest=r'C:\\Users\\39320\\Desktop\\tesi\\Computer-Vision-2020-main\\ImageSet\\test'\n",
    "\n",
    "labels = [os.path.basename(i) for i in glob.glob(pathTrain + '/*', recursive=True)]\n",
    "numberOfClasses = len(labels)\n",
    "print(\"Class number: \", numberOfClasses)\n",
    "print(\"Class names: \", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_crop(img, width, height, dim=64):\n",
    "    assert img.shape[0] >= height\n",
    "    assert img.shape[1] >= width\n",
    "    x = random.randint(0, img.shape[1] - width)\n",
    "    y = random.randint(0, img.shape[0] - height)\n",
    "    img = img[y:y+height, x:x+width]\n",
    "    resImg = cv2.resize(img, (dim,dim), interpolation=cv2.INTER_CUBIC)\n",
    "    return resImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import copy\n",
    "\n",
    "def warpAffine(src, M, dsize, from_bounding_box_only=False):\n",
    "    \"\"\"\n",
    "    Applies cv2 warpAffine, marking transparency if bounding box only\n",
    "    The last of the 4 channels is merely a marker. It does not specify opacity in the usual way.\n",
    "    \"\"\"\n",
    "    return cv2.warpAffine(src, M, dsize)\n",
    "\n",
    "def rotate_image(image, dim=64):\n",
    "    \"\"\"Rotate the image counterclockwise.\n",
    "    Rotate the image such that the rotated image is enclosed inside the\n",
    "    tightest rectangle. The area not occupied by the pixels of the original\n",
    "    image is colored black.\n",
    "    Parameters\n",
    "    ----------\n",
    "    image : numpy.ndarray\n",
    "        numpy image\n",
    "    angle : float\n",
    "        angle by which the image is to be rotated. Positive angle is\n",
    "        counterclockwise.\n",
    "    Returns\n",
    "    -------\n",
    "    numpy.ndarray\n",
    "        Rotated Image\n",
    "    \"\"\"\n",
    "    angle = random.randint(0, 360)\n",
    "    # get dims, find center\n",
    "    (h, w) = image.shape[:2]\n",
    "    (cX, cY) = (w // 2, h // 2)\n",
    "\n",
    "    # grab the rotation matrix (applying the negative of the\n",
    "    # angle to rotate clockwise), then grab the sine and cosine\n",
    "    # (i.e., the rotation components of the matrix)\n",
    "    M = cv2.getRotationMatrix2D((cX, cY), angle, 1.0)\n",
    "    cos = np.abs(M[0, 0])\n",
    "    sin = np.abs(M[0, 1])\n",
    "\n",
    "    # compute the new bounding dimensions of the image\n",
    "    nW = int((h * sin) + (w * cos))\n",
    "    nH = int((h * cos) + (w * sin))\n",
    "\n",
    "    # adjust the rotation matrix to take into account translation\n",
    "    M[0, 2] += (nW / 2) - cX\n",
    "    M[1, 2] += (nH / 2) - cY\n",
    "\n",
    "    # perform the actual rotation and return the image\n",
    "    image = warpAffine(image, M, (nW, nH), False)\n",
    "\n",
    "    resImg = cv2.resize(image, (dim,dim), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "    return resImg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataAugmentationWithCropRot(path, labels, dimension=64, d=1):\n",
    "    x = [] #New ImageSet\n",
    "    y = [] #New Label\n",
    "    for index,name in enumerate(labels):\n",
    "        s = path+'/'+name+'/{}'\n",
    "        s2 = path+'/'+name+'/'\n",
    "        temp = [s.format(i) for i in os.listdir(path+'/'+name+'/')]\n",
    "        q=0\n",
    "        for image in temp:\n",
    "            q = q+1\n",
    "            tmp = cv2.resize(cv2.imread(image,cv2.IMREAD_GRAYSCALE),(dimension,dimension),interpolation=cv2.INTER_CUBIC)\n",
    "            x.append(tmp)\n",
    "            imageio.imwrite(s2 + 'outfile1' + str(q) + str(index) + '.jpg', tmp)\n",
    "            q = q+1\n",
    "            x.append(cv2.flip(tmp,1))\n",
    "            imageio.imwrite(s2+ 'outfile2' + str(q)  + str(index)+  '.jpg', cv2.flip(tmp,1))\n",
    "            q = q+1\n",
    "            x.append(get_random_crop(tmp, dimension-24, dimension-24, dimension))\n",
    "            imageio.imwrite(s2+ 'outfile3' + str(q)+   str(index) + '.jpg', get_random_crop(tmp, dimension-24, dimension-24, dimension))\n",
    "            q = q+1\n",
    "            x.append(rotate_image(tmp, dimension))\n",
    "            imageio.imwrite(s2+ 'outfile4' + str(q) + str(index)+ '.jpg', rotate_image(tmp, dimension))\n",
    "            q = q+1\n",
    "            y.append(index)\n",
    "            y.append(index)\n",
    "            y.append(index)\n",
    "            y.append(index)\n",
    "        \n",
    "    x = np.asarray([np.reshape(im, (dimension, dimension, d)) for im in x])\n",
    "    x=x/255\n",
    "    y = np.asarray(y)\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTrain, yTrain = dataAugmentationWithCropRot(pathTrain, labels, dimension=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, yTrain = dataAugmentationWithCropRot(pathTrain, labels, dimension=224, d=1)\n",
    "xTest, yTest = dsu.loadImages(pathTest, labels, dimension=224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yTrainDummy = to_categorical(yTrain, 12)\n",
    "yTestDummy = to_categorical(yTest, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ResNet50(weights='imagenet', include_top=False)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatures(model, path, labels):\n",
    "    \n",
    "    pathImages = []\n",
    "    for label in labels:\n",
    "        s = path+'/'+label+'/{}'\n",
    "        temp = [s.format(i) for i in os.listdir(path+'/'+label+'/')]\n",
    "        pathImages = pathImages + temp\n",
    "    \n",
    "    res = []\n",
    "    count = 0\n",
    "    for p in pathImages:\n",
    "        count += 1\n",
    "        img = load_img(p, target_size=(224,224))\n",
    "        print(p)\n",
    "        img = img_to_array(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        img = imagenet_utils.preprocess_input(img)\n",
    "        res.append(img)\n",
    "        \n",
    "    images = np.vstack(res)\n",
    "    features = model.predict(images, batch_size=64)\n",
    "    featuresFlatten = features.reshape((features.shape[0], 7 * 7 * 2048))\n",
    "    \n",
    "    return images, features, featuresFlatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainImages, featureMatrix, featureArray = extractFeatures(model, pathTrain, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testImages, featureMatrixTest, featureArrayTest = extractFeatures(model, pathTest, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classif = [SVC(kernel=\"linear\") for _ in range(numberOfClasses)]\n",
    "\n",
    "currentLabel = 0\n",
    "for clf in classif:\n",
    "    print(currentLabel)\n",
    "    v = np.array([1 if label==currentLabel else 0 for label in yTrain])\n",
    "    clf = clf.fit(featureArray, v)\n",
    "    currentLabel += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = []\n",
    "for image in featureArrayTest:\n",
    "    pred = np.array([np.dot(clf.coef_,image) + clf.intercept_ for clf in classif])\n",
    "    prediction.append(np.argmax(pred))\n",
    "    \n",
    "prediction = np.asarray(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont=0\n",
    "for i in range(len(prediction)):\n",
    "    if prediction[i]==yTest[i]:\n",
    "        cont += 1\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "accuracy = cont/len(prediction)\n",
    "print(\"Accuracy value: \",accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = []\n",
    "fp = []\n",
    "fn = []\n",
    "tn = []\n",
    "for i in range(numberOfClasses):\n",
    "    tp_temp = 0\n",
    "    fp_temp = 0\n",
    "    fn_temp = 0\n",
    "    tn_temp = 0\n",
    "    \n",
    "    for j in range(len(prediction)):\n",
    "        if(prediction[j]==i and yTest[j]==i):\n",
    "            tp_temp += 1\n",
    "        if(prediction[j]==i and yTest[j]!=i):\n",
    "            fp_temp += 1\n",
    "        if(prediction[j]!=i and yTest[j]==i):\n",
    "            fn_temp += 1\n",
    "        if(prediction[j]!=i and yTest[j]!=i):\n",
    "            tn_temp += 1\n",
    "    tp.append(tp_temp)\n",
    "    fp.append(fp_temp)\n",
    "    fn.append(fn_temp)\n",
    "    tn.append(tn_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'labels':labels , 'True positive':tp,'True negative':tn,'False positive':fp,'False negative':fn}\n",
    "evaluation = pd.DataFrame(data, columns = ['labels','True positive','True negative','False positive','False negative'])\n",
    "print(\"Evaluation: \")\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = np.zeros((12,12))\n",
    "for i in range(numberOfClasses):\n",
    "    cm[i,i] = evaluation.loc[i]['True positive']\n",
    "    \n",
    "for i in range(numberOfClasses):\n",
    "    for j in range(numberOfClasses):\n",
    "        temp = 0\n",
    "        for k in range(len(yTest)):\n",
    "            if(yTest[k]==i and prediction[k]==j):\n",
    "                temp += 1\n",
    "        cm[i,j]=temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltu.plotConfusionMatrix(cm, labels, \"confusion_matrix_2\", \"images_point_fourplus/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
